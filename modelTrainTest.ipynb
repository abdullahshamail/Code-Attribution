{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau, TensorBoard\n",
    "from keras.models import Model\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = '/home/abeera/Desktop/abd/abd/data17'\n",
    "\n",
    "files = []\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        if '.cpp' in file:\n",
    "            files.append(os.path.join(r, file))\n",
    "\n",
    "# for f in files:\n",
    "#     print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56837"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputvar = {}\n",
    "counter = 0\n",
    "for x in files:\n",
    "    user = x.split('/')[-2]\n",
    "    if user not in outputvar.keys():\n",
    "        outputvar[user] = counter\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(fname):\n",
    "    f = open(fname, \"r\")\n",
    "    y = f.read()\n",
    "    f.close()\n",
    "    \n",
    "    origy = y\n",
    "    while (len(y) < 500):\n",
    "        y += origy\n",
    "        \n",
    "    f = open(fname, \"w\")\n",
    "    f.write(y)\n",
    "    f.close()\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,3):\n",
    "    print(i)\n",
    "    lengths = []\n",
    "    count = 0\n",
    "    for fil in files:\n",
    "        f = open(fil, \"r\")\n",
    "        x = f.read()\n",
    "        f.close()\n",
    "        if(len(x) <= 100):\n",
    "            files.remove(fil)\n",
    "        elif len(x) == 0:\n",
    "            print(fil)\n",
    "            files.remove(fil)\n",
    "        elif(len(x) < 500):\n",
    "            x = padding(fil)\n",
    "            lengths.append(len(x))\n",
    "        else:\n",
    "            lengths.append(len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95319\n",
      "500\n",
      "56808\n",
      "56808\n"
     ]
    }
   ],
   "source": [
    "print(max(lengths))\n",
    "print(min(lengths))\n",
    "print(len(lengths))\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/abeera/Desktop/abd/abd/data17/keshavT/main0.cpp'\n",
      " '/home/abeera/Desktop/abd/abd/data17/keshavT/main2.cpp'\n",
      " '/home/abeera/Desktop/abd/abd/data17/keshavT/main1.cpp'\n",
      " '/home/abeera/Desktop/abd/abd/data17/yhee/code10.cpp'\n",
      " '/home/abeera/Desktop/abd/abd/data17/yhee/codejam1_11.cpp'\n",
      " '/home/abeera/Desktop/abd/abd/data17/yhee/codejam1_3_21.cpp'\n",
      " '/home/abeera/Desktop/abd/abd/data17/yhee/code1_11.cpp'\n",
      " '/home/abeera/Desktop/abd/abd/data17/yhee/codejam1_10.cpp'\n",
      " '/home/abeera/Desktop/abd/abd/data17/yhee/codejam1_20.cpp'\n",
      " '/home/abeera/Desktop/abd/abd/data17/yhee/codejam1_30.cpp']\n",
      "[0 0 0 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "inp = np.array(files)\n",
    "names = []\n",
    "for fil in files:\n",
    "    names.append(outputvar[fil.split('/')[-2]])\n",
    "out = np.array(names)\n",
    "print(inp[:10])\n",
    "print(out[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, X_test, y_train, Y_test = train_test_split(inp, out, test_size=0.8, random_state = 42)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(x_train, y_train, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk(path, vocab, count):\n",
    "    for r, d, f in os.walk(path):\n",
    "        for file in f:\n",
    "            f = open(os.path.join(r, file))\n",
    "            x = f.read()\n",
    "            for line in x:\n",
    "                for letter in line:\n",
    "                    if letter not in vocab.keys():\n",
    "                        vocab[letter] = count[0]\n",
    "                        count[0] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1468]\n"
     ]
    }
   ],
   "source": [
    "vocab = {}\n",
    "count = [0]\n",
    "path = '/home/abeera/Desktop/abd/abd/data17'\n",
    "for r, d, f, in (os.walk(path)):\n",
    "    for i, dir in enumerate(d):\n",
    "        walk(os.path.join(r, dir), vocab, count)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFiles(path):\n",
    "    matrix = []\n",
    "    for p in path:\n",
    "        tmp = np.zeros((50, 10), dtype = int)\n",
    "        f = open(p)\n",
    "        for i in range(0,50):\n",
    "            for j in range(0, 10):\n",
    "                tmp[i][j] = vocab[f.read(1)]\n",
    "        matrix.append(tmp)\n",
    "    return np.array(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 50, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getFiles(['/home/abeera/Desktop/abd/abd/data17/0bstacle/main0.cpp']).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(outputvar)\n",
    "input_shape = (50, 10)\n",
    "batch_size = 1000\n",
    "def data_generator(file_paths, author_numbers):\n",
    "    batch_start = 0\n",
    "    batch_end = batch_start + batch_size\n",
    "    n = file_paths.shape[0]\n",
    "    indexes = np.arange(0, n, batch_size)\n",
    "    if n % batch_size != 0:\n",
    "        indexes = indexes[:-1] \n",
    "    while True:\n",
    "        np.random.shuffle(indexes)\n",
    "        for ind in indexes:\n",
    "            batch_start = ind\n",
    "            batch_end = batch_start + batch_size\n",
    "            myFiles = file_paths[batch_start:batch_end]\n",
    "            batch_files = getFiles(myFiles)\n",
    "            batch_authors = author_numbers[batch_start:batch_end]\n",
    "            batch_x = np.zeros((batch_size, 50, 10))\n",
    "            tmp = np.zeros((batch_size, num_classes))\n",
    "            batch_x = np.array( batch_files )\n",
    "            for i, j in enumerate(batch_authors):\n",
    "                tmp[i][j] = 1\n",
    "            batch_y = np.array( tmp )\n",
    "            yield( batch_x, batch_y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_fil = Input(shape=(input_shape), name='input_fil')\n",
    "conv = Conv1D(8, kernel_size=3, strides = 2,  activation='relu')(input_fil)\n",
    "maxP = MaxPooling1D()(conv)\n",
    "flat = Flatten()(maxP)\n",
    "output_class = Dense(num_classes, activation='softmax')(flat)\n",
    "\n",
    "model = Model(inputs=input_fil, outputs=output_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_fil (InputLayer)       (None, 50, 10)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 24, 8)             248       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 12, 8)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 11609)             1126073   \n",
      "=================================================================\n",
      "Total params: 1,126,321\n",
      "Trainable params: 1,126,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Code-Attribution'\n",
    "\n",
    "if not os.path.exists('./'+model_name):\n",
    "    os.mkdir(model_name)\n",
    "    \n",
    "adam = Adam(lr=0.001)\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=adam, \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRTensorBoard(TensorBoard):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(LRTensorBoard, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs.update({'lr': K.eval(self.model.optimizer.lr)})\n",
    "        super(LRTensorBoard, self).on_epoch_end(epoch, logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 25\n",
    "    \n",
    "checkpoint = ModelCheckpoint(model_name+'/'+model_name+'-{epoch:02d}-{val_loss:.2f}.h5', \n",
    "                             monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "cvslogger = CSVLogger(model_name+'/logs.csv', separator=',', append=True)\n",
    "#reducelr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.000001)\n",
    "tensorboard = LRTensorBoard(log_dir='./'+model_name, histogram_freq=0, write_graph=True, write_grads=1, \n",
    "                            batch_size=batch_size, write_images=True)\n",
    "\n",
    "callbacks = [checkpoint, tensorboard, cvslogger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = data_generator(X_train, Y_train)\n",
    "test_gen = data_generator(X_test, Y_test)\n",
    "val_gen = data_generator(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0010 - acc: 0.9999 - val_loss: 9.6818e-04 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00097, saving model to Code-Attribution/Code-Attribution-01-0.00.h5\n",
      "Epoch 2/25\n",
      "9/9 [==============================] - 104s 12s/step - loss: 9.0466e-04 - acc: 0.9999 - val_loss: 9.3805e-04 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00097 to 0.00094, saving model to Code-Attribution/Code-Attribution-02-0.00.h5\n",
      "Epoch 3/25\n",
      "9/9 [==============================] - 3s 324ms/step - loss: 8.4122e-04 - acc: 0.9999 - val_loss: 9.2726e-04 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00094 to 0.00093, saving model to Code-Attribution/Code-Attribution-03-0.00.h5\n",
      "Epoch 4/25\n",
      "9/9 [==============================] - 3s 321ms/step - loss: 7.9658e-04 - acc: 0.9999 - val_loss: 9.2598e-04 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00093 to 0.00093, saving model to Code-Attribution/Code-Attribution-04-0.00.h5\n",
      "Epoch 5/25\n",
      "9/9 [==============================] - 3s 315ms/step - loss: 7.4898e-04 - acc: 0.9999 - val_loss: 9.2880e-04 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00093\n",
      "Epoch 6/25\n",
      "9/9 [==============================] - 5s 526ms/step - loss: 6.9216e-04 - acc: 0.9999 - val_loss: 9.3272e-04 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00093\n",
      "Epoch 7/25\n",
      "9/9 [==============================] - 3s 380ms/step - loss: 6.2832e-04 - acc: 0.9999 - val_loss: 9.3510e-04 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00093\n",
      "Epoch 8/25\n",
      "9/9 [==============================] - 3s 374ms/step - loss: 5.5854e-04 - acc: 0.9999 - val_loss: 9.3488e-04 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00093\n",
      "Epoch 9/25\n",
      "9/9 [==============================] - 3s 362ms/step - loss: 4.7886e-04 - acc: 0.9999 - val_loss: 9.2572e-04 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00093 to 0.00093, saving model to Code-Attribution/Code-Attribution-09-0.00.h5\n",
      "Epoch 10/25\n",
      "9/9 [==============================] - 3s 373ms/step - loss: 3.9043e-04 - acc: 0.9999 - val_loss: 9.2326e-04 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00093 to 0.00092, saving model to Code-Attribution/Code-Attribution-10-0.00.h5\n",
      "Epoch 11/25\n",
      "9/9 [==============================] - 3s 372ms/step - loss: 3.0762e-04 - acc: 0.9999 - val_loss: 9.1186e-04 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00092 to 0.00091, saving model to Code-Attribution/Code-Attribution-11-0.00.h5\n",
      "Epoch 12/25\n",
      "9/9 [==============================] - 3s 367ms/step - loss: 2.1938e-04 - acc: 0.9999 - val_loss: 9.0954e-04 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00091 to 0.00091, saving model to Code-Attribution/Code-Attribution-12-0.00.h5\n",
      "Epoch 13/25\n",
      "9/9 [==============================] - 4s 391ms/step - loss: 1.4529e-04 - acc: 1.0000 - val_loss: 9.1176e-04 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00091\n",
      "Epoch 14/25\n",
      "9/9 [==============================] - 3s 366ms/step - loss: 8.9392e-05 - acc: 1.0000 - val_loss: 9.1781e-04 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00091\n",
      "Epoch 15/25\n",
      "9/9 [==============================] - 3s 369ms/step - loss: 5.9383e-05 - acc: 1.0000 - val_loss: 9.2648e-04 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00091\n",
      "Epoch 16/25\n",
      "9/9 [==============================] - 3s 375ms/step - loss: 4.1619e-05 - acc: 1.0000 - val_loss: 9.3510e-04 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00091\n",
      "Epoch 17/25\n",
      "9/9 [==============================] - 3s 373ms/step - loss: 2.9648e-05 - acc: 1.0000 - val_loss: 9.4285e-04 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00091\n",
      "Epoch 18/25\n",
      "9/9 [==============================] - 3s 378ms/step - loss: 2.4512e-05 - acc: 1.0000 - val_loss: 9.4154e-04 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00091\n",
      "Epoch 19/25\n",
      "9/9 [==============================] - 4s 412ms/step - loss: 2.1496e-05 - acc: 1.0000 - val_loss: 9.4482e-04 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00091\n",
      "Epoch 20/25\n",
      "9/9 [==============================] - 3s 369ms/step - loss: 2.0267e-05 - acc: 1.0000 - val_loss: 9.4402e-04 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00091\n",
      "Epoch 21/25\n",
      "9/9 [==============================] - 3s 375ms/step - loss: 1.9370e-05 - acc: 1.0000 - val_loss: 9.4602e-04 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00091\n",
      "Epoch 22/25\n",
      "9/9 [==============================] - 3s 377ms/step - loss: 1.8222e-05 - acc: 1.0000 - val_loss: 9.4638e-04 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00091\n",
      "Epoch 23/25\n",
      "9/9 [==============================] - 3s 370ms/step - loss: 1.7396e-05 - acc: 1.0000 - val_loss: 9.4749e-04 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00091\n",
      "Epoch 24/25\n",
      "9/9 [==============================] - 3s 378ms/step - loss: 1.7482e-05 - acc: 1.0000 - val_loss: 9.4802e-04 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00091\n",
      "Epoch 25/25\n",
      "9/9 [==============================] - 3s 379ms/step - loss: 1.7179e-05 - acc: 1.0000 - val_loss: 9.4956e-04 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00091\n"
     ]
    }
   ],
   "source": [
    "hist1 = model.fit_generator(train_gen, epochs=epochs, steps_per_epoch=len(Y_train)//batch_size, \n",
    "                           validation_data=val_gen, validation_steps=len(Y_val)//batch_size, \n",
    "                           callbacks=callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = data_generator(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-56e518954b90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1520\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1522\u001b[0;31m             verbose=verbose)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(model, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;31m# Compatibility with the generators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(test_gen, steps=len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45447, 50, 10)\n"
     ]
    }
   ],
   "source": [
    "xtestdata = getFiles(X_test)\n",
    "print(xtestdata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(xtestdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45447, 11609)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "myPreds = []\n",
    "for i in preds:\n",
    "    myPreds.append(np.argmax(i))\n",
    "myPreds = np.array(myPreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45447,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myPreds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5885"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myPreds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 21.779215349748057\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(myPreds.shape[0]):\n",
    "    if myPreds[i] == Y_test[i]:\n",
    "        count += 1\n",
    "\n",
    "acc = (count / myPreds.shape[0]) * 100\n",
    "print(\"Accuracy\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
